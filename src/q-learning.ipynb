{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0962260b-41f8-42aa-9293-970a1d463838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f4463f4f-1919-4976-9412-639991a8463a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "Number of states: 59\n",
      "Observation space shape: ()\n",
      "Number of actions: 4\n"
     ]
    }
   ],
   "source": [
    "# Environment parameters\n",
    "#env = gym.make('CartPole-v0')\n",
    "#env = gym.make('Pong-v4')\n",
    "#enviroment = gym.make(\"Taxi-v3\").env\n",
    "enviroment = gym.make('FrozenLake8x8-v1', is_slippery=False, map_name='8x8')\n",
    "enviroment.render()\n",
    "num_states = enviroment.observation_space.sample()\n",
    "num_actions = enviroment.action_space.n\n",
    "print(f\"Number of states: {num_states}\")\n",
    "print(f\"Observation space shape: {enviroment.observation_space.shape}\")\n",
    "print(f\"Number of actions: {num_actions}\")\n",
    "#print(f\"Action meanings: {enviroment.unwrapped.get_action_meanings()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b63d6a61-775e-4fcf-945a-5c527fc441bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "gamma = 0.6\n",
    "epsilon = 0.1\n",
    "q_table = np.zeros([enviroment.observation_space.n, enviroment.action_space.n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a8c4a115-9ff8-4ba4-87c0-312832b1fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.7\n",
    "gamma = 0.5\n",
    "epsilon = 0.5\n",
    "q_table = np.zeros([enviroment.observation_space.n, enviroment.action_space.n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bbe3026b-41d9-48a2-aefa-c9d02b18a736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 500\n",
      "{'prob': 1.0, 'TimeLimit.truncated': True}\n",
      "0.0\n",
      "2\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "F\u001b[41mF\u001b[0mFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "**********************************\n",
      "Training is done!\n",
      "\n",
      "**********************************\n"
     ]
    }
   ],
   "source": [
    "num_of_episodes = 500#000\n",
    "\n",
    "for episode in range(0, num_of_episodes):\n",
    "    # Reset the enviroment\n",
    "    state = enviroment.reset()\n",
    "\n",
    "    # Initialize variables\n",
    "    reward = 0\n",
    "    terminated = False\n",
    "    \n",
    "    while not terminated:\n",
    "        # Take learned path or explore new actions based on the epsilon\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = enviroment.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(q_table[state])\n",
    "\n",
    "        # Take action    \n",
    "        next_state, reward, terminated, info = enviroment.step(action) \n",
    "        \n",
    "        # Recalculate\n",
    "        q_value = q_table[state, action]\n",
    "        max_value = np.max(q_table[next_state])\n",
    "        new_q_value = (1 - alpha) * q_value + alpha * (reward + gamma * max_value)\n",
    "        \n",
    "        # Update Q-table\n",
    "        q_table[state, action] = new_q_value\n",
    "        state = next_state\n",
    "        \n",
    "    if (episode + 1) % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(\"Episode: {}\".format(episode + 1))\n",
    "        print(info)\n",
    "        print(reward)\n",
    "        print(action)\n",
    "        enviroment.render()\n",
    "\n",
    "print(\"**********************************\")\n",
    "print(\"Training is done!\\n\")\n",
    "print(\"**********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d3b482ac-f72e-40e0-bd51-b5b25751c8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 102\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "**********************************\n",
      "Results\n",
      "**********************************\n",
      "Epochs per episode: 101.0\n",
      "Penalties per episode: 101.0\n"
     ]
    }
   ],
   "source": [
    "### total_epochs, total_penalties = 0, 0\n",
    "num_of_episodes = 5\n",
    "patience = 100\n",
    "total_penalties = 0\n",
    "total_epochs = 0\n",
    "for _ in range(num_of_episodes):\n",
    "    state = enviroment.reset()\n",
    "    epochs = 0\n",
    "    penalties = 0\n",
    "    reward = 0\n",
    "    \n",
    "    terminated = False\n",
    "    \n",
    "    while not terminated:\n",
    "        action = np.argmax(q_table[state])\n",
    "        state, reward, terminated, info = enviroment.step(action)\n",
    "        print(reward)\n",
    "        print(info)\n",
    "        if reward <= 0:\n",
    "            penalties += 1\n",
    "        \n",
    "        epochs += 1\n",
    "        if (epochs + 1) % 1 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Episode: {}\".format(epochs+ 1))\n",
    "            enviroment.render()\n",
    "\n",
    "        if epochs > patience:\n",
    "            terminated = True\n",
    "    total_penalties += penalties\n",
    "    total_epochs += epochs\n",
    "\n",
    "print(\"**********************************\")\n",
    "print(\"Results\")\n",
    "print(\"**********************************\")\n",
    "print(\"Epochs per episode: {}\".format(total_epochs / num_of_episodes))\n",
    "print(\"Penalties per episode: {}\".format(total_penalties / num_of_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3fd53e6d-99ec-495a-8de6-210eb57968f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_policy(policy):\n",
    "    interpretation = {\n",
    "        0: \"<\",\n",
    "        1: \"v\",\n",
    "        2: \">\",\n",
    "        3: \"^\",\n",
    "    }\n",
    "    [print([interpretation[j] for j in i], \"\\n\") for i in policy]\n",
    "    return\n",
    "\n",
    "def calculate_policy(q_table, dim):\n",
    "    policy =np.zeros((dim,dim))\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            #print(np.where(q_table[i*dim+j] == np.max(q_table[i*dim+j])))\n",
    "            action =  np.where(q_table[i*dim+j] == np.max(q_table[i*dim+j]))[0]\n",
    "            if type(action) == np.ndarray:\n",
    "                action=action[0]\n",
    "            policy[i][j] = action\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cb7577b4-c2d2-461c-96a1-cfcc4bd03a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = calculate_policy(q_table, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b27395e7-c042-4249-b20f-a4bad7fcd849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [2. 1. 1. 0.]\n",
      " [0. 2. 2. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eee2c2c0-92b6-4e7a-84de-9410fb469f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v', '>', 'v', '<'] \n",
      "\n",
      "['v', '<', 'v', '<'] \n",
      "\n",
      "['>', 'v', 'v', '<'] \n",
      "\n",
      "['<', '>', '>', '<'] \n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(print_policy(policy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
